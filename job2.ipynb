{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcVMUEzLg0peVnuxWq1rTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luminyanko/DSL/blob/main/job2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XArGNzfUBt-"
      },
      "source": [
        "# Job #2 \n",
        "Savenko Valeriia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGATo2RUXRKa"
      },
      "source": [
        "Let's say that context free grammar is such this:\n",
        "```\n",
        "{'toks': set(token), 'vars': dict(var: definition), 'hvar': var}\n",
        "token : (class, value)\n",
        "class : int\n",
        "value : str\n",
        "var : str                 # non-terminal name\n",
        "definition : list(rule)\n",
        "rule : list(var | token)  # right part of the rule\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Bne8-Q-ulx"
      },
      "source": [
        "Non-terminals and corresponding rules are passed in a cycle. If the non-terminal is not foreign, it remains and is added to the new dictionary (it is checked whether such does not already exist in the dictionary), if it is foreign - it is ignored. Rules that do not correspond to non-third-party non-terminals are also moved: if the rule contains a third-party non-terminal, it is rejected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZdJKProY6La"
      },
      "source": [
        "def remove_non_terminal(grammar):\n",
        "  not_existing_sym = search_not_existing_sym(grammar)\n",
        "  new_grammar = copy.deepcopy(grammar)\n",
        "  toks = grammar['toks']\n",
        "  vars = grammar['vars']\n",
        "  new_vars = dict()\n",
        "\n",
        "  for nonterminals, definitions in vars.items():\n",
        "    if nonterminals in not_existing_sym:\n",
        "             for rules in definitions:\n",
        "                 if check_token_for_rule(rules, toks, not_existing_sym):\n",
        "                    if nonterminals in new_vars.keys():\n",
        "                        new_vars[nonterminals].append(rules)\n",
        "                    else:\n",
        "                        new_vars[nonterminals] = list()\n",
        "                        new_vars[nonterminals].append(rules)\n",
        "  new_grammar['vars'] = new_vars\n",
        "  return new_grammar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHxP0bPBCW4U"
      },
      "source": [
        "Non-third-party terminals are defined by an auxiliary function that checks whether the non-terminal has only tokens and / or already known non-third-party non-terminals in the rule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5llVZxaL_Uzk"
      },
      "source": [
        "def search_not_existing_sym(grammar):\n",
        "    toks = grammar['toks']\n",
        "    vars = grammar['vars']\n",
        "    not_existing_sym = list()\n",
        "    flag = True\n",
        "    while flag:\n",
        "        flag = False\n",
        "        for nonterminals, definitions in vars.items():\n",
        "            for rule in definitions:\n",
        "                if check_token_for_rule(rule, toks, not_existing_sym):\n",
        "                    if nonterminals not in not_existing_sym:\n",
        "                        not_existing_sym.append(nonterminals)\n",
        "                        flag = True\n",
        "    return not_existing_sym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03HPTfZACbdh"
      },
      "source": [
        "Function that checks the rules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrWO0A5LBLtJ"
      },
      "source": [
        "def check_token_for_rule(rule, tokens, _list):\n",
        "    for partOfRule in rule:\n",
        "        if partOfRule in tokens or partOfRule in _list:\n",
        "            pass\n",
        "        else:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tvdrfWUETM4"
      },
      "source": [
        "Here's an examlple: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45GvEJJCvF5",
        "outputId": "8274760b-72cc-4f83-d978-e1a48ee94294"
      },
      "source": [
        "import copy\n",
        "import pprint\n",
        "grammar = {\n",
        "    'toks': set( [\n",
        "        ('class1', 'a1'), \n",
        "        ('class1', 'a2'), \n",
        "        ('class1', 'a3'), \n",
        "        ('class2', 'b1'), \n",
        "        ('class2', 'b2'), \n",
        "        ('class3', 'c1')\n",
        "    ] ),\n",
        "    'vars': {\n",
        "        'S' : [['N', ('class3', 'c1')], \n",
        "               ['N', 'M'],\n",
        "               ['B', ('class1', 'a3'), 'C'],\n",
        "               ['F', ('class2', 'b1'), ('class1', 'a2')]],\n",
        "        'A' : [[]],\n",
        "        'B' : [['A']],\n",
        "        'C' : [['B']],\n",
        "        'N' : [['M']],\n",
        "        'M' : [['N']],\n",
        "        'F' : [[('class1', 'a3'), ('class2', 'b1'), ('class2', 'b2'), ('class3', 'c1')]]\n",
        "    },\n",
        "    'hvar': 'S'\n",
        "}\n",
        "new_grammar = remove_non_terminal(grammar)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(new_grammar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'hvar': 'S',\n",
            "    'toks': {   ('class1', 'a1'),\n",
            "                ('class1', 'a2'),\n",
            "                ('class1', 'a3'),\n",
            "                ('class2', 'b1'),\n",
            "                ('class2', 'b2'),\n",
            "                ('class3', 'c1')},\n",
            "    'vars': {   'A': [[]],\n",
            "                'B': [['A']],\n",
            "                'C': [['B']],\n",
            "                'F': [   [   ('class1', 'a3'),\n",
            "                             ('class2', 'b1'),\n",
            "                             ('class2', 'b2'),\n",
            "                             ('class3', 'c1')]],\n",
            "                'S': [   ['B', ('class1', 'a3'), 'C'],\n",
            "                         ['F', ('class2', 'b1'), ('class1', 'a2')]]}}\n"
          ]
        }
      ]
    }
  ]
}