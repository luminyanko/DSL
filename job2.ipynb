{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLz3CXuip8t4zbNOjPPvQW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luminyanko/DSL/blob/main/job2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XArGNzfUBt-"
      },
      "source": [
        "# Job #2 \n",
        "Savenko Valeriia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGATo2RUXRKa"
      },
      "source": [
        "Let's say that context free grammar is such this:\n",
        "```\n",
        "{'toks': set(token), 'vars': dict(var: definition), 'hvar': var}\n",
        "token : (class, value)\n",
        "class : int\n",
        "value : str\n",
        "var : str                 # non-terminal name\n",
        "definition : list(rule)\n",
        "rule : list(var | token)  # right part of the rule\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Bne8-Q-ulx"
      },
      "source": [
        "Non-terminals and corresponding rules are passed in a cycle. If the non-terminal is not foreign, it remains and is added to the new dictionary (it is checked whether such does not already exist in the dictionary), if it is foreign - it is ignored. Rules that do not correspond to non-third-party non-terminals are also moved: if the rule contains a third-party non-terminal, it is rejected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZdJKProY6La"
      },
      "source": [
        "def remove_non_terminal(grammar):\n",
        "  not_existing_sym = search_not_existing_sym(grammar)\n",
        "  new_grammar = copy.deepcopy(grammar)\n",
        "  toks = grammar['toks']\n",
        "  vars = grammar['vars']\n",
        "  new_vars = dict()\n",
        "\n",
        "  for nonterminals, definitions in vars.items():\n",
        "    if nonterminals in not_existing_sym:\n",
        "             for rules in definitions:\n",
        "                 if check_token_for_rule(rules, toks, not_existing_sym):\n",
        "                    if nonterminals in new_vars.keys():\n",
        "                        new_vars[nonterminals].append(rules)\n",
        "                    else:\n",
        "                        new_vars[nonterminals] = list()\n",
        "                        new_vars[nonterminals].append(rules)\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHxP0bPBCW4U"
      },
      "source": [
        "Non-third-party terminals are defined by an auxiliary function that checks whether the non-terminal has only tokens and / or already known non-third-party non-terminals in the rule."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5llVZxaL_Uzk"
      },
      "source": [
        "def search_not_existing_sym(grammar):\n",
        "    toks = grammar['toks']\n",
        "    vars = grammar['vars']\n",
        "    not_existing_sym = list()\n",
        "    flag = True\n",
        "    while flag:\n",
        "        flag = False\n",
        "        for nonterminals, definitions in vars.items():\n",
        "            for rule in definitions:\n",
        "                if check_token_for_rule(rule, toks, not_existing_sym):\n",
        "                    if nonterminals not in not_existing_sym:\n",
        "                        not_existing_sym.append(nonterminals)\n",
        "                        flag = True\n",
        "    return not_existing_sym"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03HPTfZACbdh"
      },
      "source": [
        "Function that checks the rules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrWO0A5LBLtJ"
      },
      "source": [
        "def check_token_for_rule(rule, tokens, _list):\n",
        "    for partOfRule in rule:\n",
        "        if partOfRule in tokens or partOfRule in _list:\n",
        "            pass\n",
        "        else:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tvdrfWUETM4"
      },
      "source": [
        "Here's an examlple: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45GvEJJCvF5",
        "outputId": "f3cc78d8-ec7a-4de8-fe0d-90bc3a4eae94"
      },
      "source": [
        "import copy\n",
        "import pprint\n",
        "grammar = { 'toks': list(\n",
        "                    [(0, ' '),\n",
        "                     (11, 'aa'),\n",
        "                     (12, 'bb'),\n",
        "                     (21, 'ab'),\n",
        "                     (22, 'cc')]\n",
        "                    ),\n",
        "            'vars': {\n",
        "                'A': [['B', (11, 'aa')],\n",
        "                      ['D'],\n",
        "                      ['F', (12, 'bb')]],\n",
        "                'B': [['B'],\n",
        "                      ['F', (21, 'ab')]],\n",
        "                'C': [['C'],\n",
        "                      ['A',(22, 'cc')],\n",
        "                      ['F', (11, 'aa')]],\n",
        "                'D': [[(0, ' ')]],\n",
        "                'F': [\n",
        "                      ['B', (21, 'ab')],\n",
        "                      ['F', (12, 'bb')]]\n",
        "                    },\n",
        "            'hvar': 'A',\n",
        "            }\n",
        "remove_non_terminal(grammar)\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(grammar)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'hvar': 'A',\n",
            "    'toks': [(0, ' '), (11, 'aa'), (12, 'bb'), (21, 'ab'), (22, 'cc')],\n",
            "    'vars': {   'A': [['B', (11, 'aa')], ['D'], ['F', (12, 'bb')]],\n",
            "                'B': [['B'], ['F', (21, 'ab')]],\n",
            "                'C': [['C'], ['A', (22, 'cc')], ['F', (11, 'aa')]],\n",
            "                'D': [[(0, ' ')]],\n",
            "                'F': [['B', (21, 'ab')], ['F', (12, 'bb')]]}}\n"
          ]
        }
      ]
    }
  ]
}